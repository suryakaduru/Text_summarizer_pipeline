# ğŸ“ Modular Text Summarization Pipeline

A modular and extensible text summarization application powered by a self-hosted Large Language Model (LLM). This project enables efficient data loading, summarization, evaluation, and analysis in a streamlined pipeline.

---

## ğŸ“Œ Overview

This project aims to build a modular text summarization system with the following components:

- **Data Loader**: Loads and prepares the dataset.
- **Model**: Loads and configures the summarization model.
- **Pipeline**: Orchestrates data flow and executes summarization.
- **Evaluator**: Evaluates summaries using metrics like ROUGE.
- **Main Runner**: CLI script to run the complete pipeline.

---

## ğŸ—‚ï¸ Project Structure

```
text_summarization_pipeline/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml             # Configuration file for the pipeline
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus.7z                # Dataset archive (e.g., SAMSum)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py           # Loads and preprocesses data
â”‚   â”œâ”€â”€ model.py                 # Summarization model configuration
â”‚   â”œâ”€â”€ pipeline.py              # Coordinates the summarization steps
â”‚   â”œâ”€â”€ evaluator.py             # Evaluation and metrics analysis
â”‚   â””â”€â”€ main.py                  # Main CLI script to run the pipeline
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test.py                  # Test script with ROUGE-based evaluation
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
```

---

## âš™ï¸ Setup Instructions

### âœ… Prerequisites

- Python 3.8 or higher
- Git
- Pip

### ğŸ§­ Steps

1. **Clone the Repository**

```bash
git clone https://github.com/your-username/text_summarization_pipeline.git
cd text_summarization_pipeline
```

2. **Install Dependencies**

```bash
pip install -r requirements.txt
```

3. **Download and Prepare Dataset**

- Download the dataset (e.g., SAMSum) and place it inside the `data/` directory.
- Ensure the dataset is named correctly (e.g., `corpus.7z`).

4. **Configure the Pipeline**

- Edit `configs/default.yaml` to set paths, model settings, logging preferences, etc.

---

## ğŸš€ Running the Pipeline

Run the full summarization pipeline:

```bash
python src/main.py
```

This script will:
- Load and preprocess the dataset
- Run the summarization model
- Evaluate generated summaries using ROUGE
- Log and store results

---

## âœ… Testing

Run test cases with:

```bash
python tests/test.py
```

The test script will:
- Load a subset of the dataset
- Generate summaries
- Evaluate using ROUGE
- Save results to `test_results.csv`

---

## ğŸ“Š Insights

### ğŸ” Analysis of Results

- **ROUGE Scores**: Measure similarity between generated and reference summaries.
- **Dialogue Complexity**: Number of speakers and length of dialogue affect summarization quality.

### âš ï¸ Observations

- **Challenging Samples**: Multi-speaker or long dialogues are harder to summarize.
- **Common Issues**: Missed key points, irrelevant outputs.

---

## ğŸ”§ Preprocessing & Postprocessing

- **Preprocessing**: Tokenization, normalization, stop-word removal.
- **Postprocessing**: Filtering filler phrases, grammar correction.

---

## âš ï¸ Limitations & Improvements

### Limitations

- Performance may vary based on dataset and model choice.
- Dataset size may limit generalization capabilities.

### Future Improvements

- Fine-tune on domain-specific data.
- Add hyperparameter tuning modules.
- Incorporate advanced metrics like **BERTScore**.

---

## ğŸŒŸ Optional Enhancements

- **ğŸ” Hyperparameter Tuning**: Add grid/random search for better performance.
- **ğŸ“ˆ Visualization**: Create performance dashboards.
- **ğŸ§  Fine-tuning**: Adapt model to your custom dataset.

---

Feel free to contribute or customize the pipeline to suit your needs. This modular structure makes it easy to extend and experiment with different summarization models and evaluation techniques.
